# 项目说明文档  Project Specification

## 一、项目内容与总体目标（Project Goal）

本项目为工业设计专业大学生的毕业设计。题目：结合健康监测与认知训练的老年陪伴机器人交互体验设计研究（牢记）最终需产出可交互的老年陪伴机器人原型。

主要工作任务及内容：
本课题围绕 **健康监测+认知训练的老年陪伴机器人** 开展交互体验设计研究。通过文献调研、用户访谈与需求分析，明确老年人在 **健康管理、情感陪伴及认知维持** 方面的核心需求。基于此，提出机器人 **健康监测、智能提醒、认知训练互动** 等功能框架，并构建用户旅程与交互流程。完成机器人外观造型、界面UI、情感化表达等设计方案，制作低/高保真原型并进行可用性测试，结合反馈进行优化，最终形成完整的交互体验设计成果。

具体目标：开发一个面向机构养老场景的多模态交互陪伴机器人系统原型，具备 “**投影式认知交互 + 非接触式健康监测 + 情感陪伴机制**” 的联动框架，产出 **基于老人状态感知的自适应交互系统**

机器人的身体上具备一个屏幕（使用安卓平板，该平板自带一个前置的摄像头）和一个投影仪以及和一个外置摄像头。

系统在我的电脑上运行，是一个包含前后端的项目（C:\Users\purriste\Desktop\PYProject\rppg），后端用python（D:/anaconda/envs/rppg/python.exe，环境名：rppg），前端用nuxt-vue。平板上安装了ip webcam，电脑和平板置于同一个网络下，平板将前置摄像头的视频传到电脑（例如http:192.168.137.97:8080），该视频用于状态的采集，①情绪状态 ②心率（rppg）hrv③环境数据（光强、是否有人、有多少人、人与摄像头距离、人脸识别等）④人的身体状态（坐立状态、活动量、身体动作、头部动作、动作频率（行为节奏）、眼部：眨眼频率、是否注视屏幕、注视时间、游离频率、交互频率、注意力/反应力），Python获取视频后会进行处理，获得这些数据。而电脑连接的外置摄像头，会拍摄投影到地面的UI，视频传到Python，用于检测人在地面UI上的行为和位置，从而形成交互（空间互动投影）（这部分的难度在于，如何正确的识别人的位置，并与UI上交互组件位置对应）。

本研究重点关注：是否能够通过多模态感知形成**状态判断**，做到无感的状态监测，是否能够基于状态动态调节**交互与训练**，是否能让老人**愿意参与并持续参与**，以及基于状态的**主动交互**。合理设计交互的触发时机、交互的内容、交互的方式与形式，不仅做到健康和认知层面的守护，也提供情感支持。

---

## 二、核心项目要求（Project Requirements）

### 1. 三个能力必须联动，而非独立存在

本项目中的三项能力需构成闭环：

- **健康监测**：提供生理与行为状态线索
- **情感陪伴**：提供长期互动与情绪反馈机制
- **认知训练**：作为主要交互任务，并根据状态动态调整

### 2. 投影交互是主要交互方式

系统的核心交互形式为：

- 使用投影仪将认知训练界面投影到地面
- 老人通过 **脚步 / 站位 / 停留** 与投影界面交互
- 同时，可以在平板上通过传统的点击交互

### 3.视频识别与显示，必须高效、流畅、准确

视频流必须极度流畅（不能有明显延迟），且状态识别准确度要高，特别要解决侧脸、低头等非正脸/低光照、多人等复杂环境变化场景下的识别失败问题。

## 三、系统整体结构（System Architecture）

### 1. 感知层（Sensing Layer）

- RGB 摄像头
  - **平板端摄像头**
    - rPPG 心率估计
    - 情绪 / 面部状态趋势
    - 上半身姿态与参与度
  - **地面交互摄像头（外接摄像头）**
    - 识别人与投影界面的交互
    - 判断脚步位置、停留、遮挡行为

### 2. 状态理解层（State Interpretation）

- 生理状态趋势判断（非医疗诊断）
- 情绪与参与度变化趋势
- 异常或疲劳行为信号

输出为状态参考信号，而非确定性结论。

### 3. 交互与决策层（Interaction & Control）

接入一个大语言模型以及运用其他工具，实现对整个系统的控制，实现以下功能：1.实现“阿康阿康”唤醒，与老人进行语言/文字交流。2.记忆能力，记录与老人的对话，以及老人平时在该系统的操作（如收听了某歌曲，观看了某电视剧），从而了解老人的偏好，实现个性化的问答。3.将这些记忆运用于认知训练，开发基于记忆与偏好的认知训练游戏。4.实现页面的控制与跳转，如老人说“阿康阿康，我想看《西游记》”，大模型能够跳转到相应的页面。
该模型需要能够实现：1.调节认知训练内容与参数（个性化内容、难度、节奏、持续时间）2.调节情感反馈方式（语音语气、鼓励 / 放缓 / 休息提示）

---

## 四、UI 与交互界面结构（UI Structure）

### 1. 平板端 UI（机器人系统界面）

色彩规范：旨在营造 “灵动、简洁、活力、温暖、适老化” 的氛围

核心主题色 (60%)：#FF7222 (活力橙) —— 用于 Logo、主按钮及核心品牌元素，赋予产品温暖感。

功能提示色 (15%)：

1、 #33B555 (安全绿) —— 用于表现“情绪正向、挑战适中”等。

2、 #FB4422 (警戒红) —— 用于表现“情绪负面、压力过载”等。

辅助色 (20%)： #FFD111 (温暖黄) & #2AAADD (清爽蓝)

点缀色 (5%)： #1DD1BB (薄荷绿) & #7555FF (极光紫)

#### UI 设计与适配方案：16:10 比例与跨平台兼容

机器人身体上的屏幕是安卓平板（2560*1600），必须严格遵循 16:10 的显示比例。同时，系统又是在电脑上开发的，必须解决在不同缩放比例（如电脑 Edge 浏览器 100% 缩放）下，UI 不会因为高度不足而导致底部信息丢失（溢出）的问题，确保排版灵动且温暖。

【可参考的解决方法】：
容器级比例锚定：在 app.vue 根组件中，我构建了一个名为 .tablet 的核心容器，利用 CSS 的 aspect-ratio: 16 / 10; 属性强制锁定比例。
视口单位（vh/vw）与 Flex 自适应布局：
解决溢出：放弃了写死像素（px）高度，转而使用 flex: 1 配合 min-height: 0。这确保了视频区域能够根据剩余空间动态收缩。
视口锁定：将整个容器高度定为 100vh，即使电脑端缩放比例改变，UI 也会在保持 16:10 的前提下自动等比例缩放，并居中显示，永远不会出现“底部字看不见”或“需要滚动条”的情况。
视频无缝填充：针对“视频窄、有黑边”的问题，使用了 object-fit: cover;。这确保了无论摄像头采集的原始比例如何，画面都会充满 16:10 的容器，提供沉浸式的视觉体验。

- 通过局域网访问
- 作为机器人的控制与反馈界面
- 功能包括：
  - 启动 / 停止认知训练
  - 人脸识别，登录不同账户
  - 语音助手，一声“阿康阿康”即可唤醒
  - 分为五大板块：主页、健康、娱乐、认知、个人账户与设置，采用侧边栏形式，

#### Ⅰ 主页

1. 日期天气显示
2. 语音通话
3. 一键呼叫
4. 健康、娱乐、益智 三大入口
5. 智能服务助手（阿康（Akon）动态形象）语音唤醒，智能响应。

#### Ⅱ 健康板块

1.健康看板，可视化查看自己的健康状态（例如：情绪健康、睡眠健康、清醒次数、起夜、睡眠时长、睡眠分析建议、活动量、活动小时数、锻炼时长、心率、hrv、静息心率等等）

2.运动课程（八段锦、太极、羽毛球、慢跑（跑前热身、科学慢跑、跑后拉伸放松）等等）

3.生活建议（饮食建议等）

#### Ⅲ 娱乐板块（将老人平时看过/听过的内容融入认知训练）

1.影视功能（电视剧电影播放）

2.音乐功能（民歌、戏曲、收音机、相声、听书等）

3.舞蹈功能（广场舞、交际舞）

4.报纸杂志资讯（时政、历史、军事、小说、健康）

5.回忆相册（可能会偏重这个，与认知训练进行联动）

#### Ⅲ 益智板块

1.认知训练/游戏（听音猜歌名、色词测试、打地鼠等）

2.认知看板（训练时长、训练效果、趋势等等）

3.学习（园艺种植、烹饪烘焙、琴棋书画、手工（织毛衣、刺绣、剪纸、折纸、串珠））

---

### 2. 投影端 UI（认知训练界面）

- 通过投影仪投射到地面
- 展示内容：
  - 认知训练游戏
  - 大尺寸、低精度操作区域
- 不承载复杂信息，仅用于交互任务本身

---

## 五、认知训练形式 示例：色词测试（Stroop Test）

- 投影界面显示：
  - 一个带颜色的文字（如红色的“黄”）
  - 多个大尺寸选项区域
- 用户任务：
  - 选择文字的**颜色**而非文字含义
- 交互方式：
  - 通过脚踩或停留在对应投影区域完成选择

## 七、最终预期产出

### 1. 调研报告（背书）

1.文献调研
2.用户调研与访谈（用户画像 + 问题地图）
3.竞品调研
4.技术调研

### 2. 设计报告

1.用户旅程图（养老机构老年人的一天，真实的需求与痛点，触点）
2.利益相关者地图
3.系统架构图（触点、前台、前端、后端）
4.技术路径图
5.交互流程图（交互泳道图）
6.UI kit（设计规范）与UI展示
7.服务蓝图
8.使用场景图
9.产品大图展示
10.结构示意图、尺寸、三视图
11.可能有：数据流与隐私边界、
顺序不一定是这样，会更有逻辑

### 3. UI设计

1.风格、氛围、配色与字体
2.系统架构（UI系统）

### 4. 交互原型

### 5. 建模渲染

### 6. 原型搭建与可用性测试

1.是否满足老年人需求
2.可用、易用、愿意用
3.真的有用，验证对认知的积极作用

### 7. 原型优化

### 8. 展览物料

开题报告需要具备：
一、本课题研究（设计）的目的：
二、研究（设计）现状和发展趋势：
三、研究（设计）的重点与难点，拟采用的途径（研究手段）：
四、研究（设计）进度计划：
五、参考文献：

我的文献应该可以大致分为几个部分
一、认知训练
1.认知训练对老年人是否真的有用？
2.怎么通过实验/可用性测试等检测认知训练有用（特别是短期实验/主观问卷量表，因为我可能只进行一次短期的可用性测试）？
3.有哪些老年人的认知训练方法被认证是有效的？
4.这些有用的方法（比如记忆训练、快速处理等）通过什么机制发挥作用？
5.这些训练方法是否有明确的定义和设计方法？（这将帮助我设计认知训练游戏）
6.哪些因素影响认知训练效果？（比如分级的动态的难度调节、参与意愿、脑体结合、投影的方式、回忆熟悉的内容、音乐、视觉效果、多人参与等）（这非常有用，关乎是我的核心设计点）
7.认知训练模型（认知训练→状态感知→训练效果总结→改进训练方法→下次认知训练）
二、生理状态与心理状态
1.老年人存在什么健康需求和心理需求（慢性病、摔倒、孤独感等）
2.老年人的生理状态怎么检测（现有健康监测技术与设备：血压、血糖、心率等，比如手环等穿戴式的设备，老年人的接受程度。非接触式的无感监测形式）
3.非接触式的无感监测的技术，如rppg的心率检测、摄像头检测运动量和灵活度、摔倒（动作、体态）监测，（这方面我主要想为“通过老年人相对平时的异常状态/数据/行为来推断健康状态，实现健康监测的目的”做背书）
4.rppg的方式是否可行？开源的算法。
5.怎么提高rppg的准确率（受运动、光照条件影响特别大，鲁棒性需要提升）（有深度学习算法，需评估实现难度，看看我这个项目是否合适）
6.是否能够相对平时的异常状态/数据/行为来推断健康状态
7.开源的动作行为监测算法，以及提高准确度的方法
8.老年人的心理状态怎么检测（情绪、认知游戏的参与度）
9.情绪识别算法以及效率提高方法
10.情绪与参与程度的映射方式，哪些情绪说明当前太简单，哪些情绪说明当前太困难。
三、适老化交互
1.陪伴型机器人怎么建立信任感，让老人愿意使用
2.陪伴型机器人怎么提供认知维护、健康监测和情绪支持
3.适老化的UI规范（字体、颜色、按钮大小、菜单深度等）
4.老年人与语音交互（证明语音交互是适老的，怎么让语音交互更适老，语音交互的语速、语气、语调、称呼、性别等）
5.老年人与投影交互（证明投影交互是适老的，怎么让投影交互更适老）
6.怎么提高投影交互的体验（识别准确率、实时反馈等）

我最核心的价值就是“让老人愿意持续使用”，为了达到这一目的，我首先从心理和生理层面分析，为什么老年人不愿意使用现有的健康监测和认知训练还有情感陪伴的相关产品，（1.老年人不习惯佩戴现有的手环/穿戴式设备2.他们不希望产生“我身体不行了，需要被监测照顾”“我认知在衰退”的感觉3.老人普遍存在内心孤独，但现有产品没有解决他们需要被平等对待、需要尊重、需要个人隐私的问题，且机器无法代替真正的人走进老人心里），而我的陪伴型机器人本身的定位，不是冷冰冰的工具和监视器，但也不是取代真实的人，而是一种智能的具身陪伴。我不知道怎么很好的定义它，但我想它这种具身智能的形式，才是科技最本质的目的，服务于人，带给人美好的生活。

一、本课题设计（研究）的目的
近年来老年人在健康管理、认知维持与情感陪伴方面的需求不断增长，然而相关智能产品普遍存在老人使用意愿低且难以长期坚持的问题。除操作复杂性与技术门槛外，更深层的原因在于现有产品的形态与交互方式容易强化“能力退化”“被训练”“被监测”的心理暗示，忽视老年人对尊严、情感安全与平等关系的需求，从而引发抵触情绪，削弱其使用意愿。
本课题从交互载体与人机关系层面进行重新思考。陪伴型机器人作为一种具身智能形态，具备持续、低干扰的在场感知与互动的优势，能够将健康监测与认知训练自然嵌入日常陪伴之中，从而弱化技术干预感，建立更符合老年人心理预期的互动关系。
因此，本课题以“结合健康监测与认知训练的老年陪伴机器人”为研究对象，聚焦陪伴型机器人在老年日常情境中的感知与互动机制，探索如何通过对老年人状态、行为与偏好的持续理解，构建更具适应性与个性化的陪伴体验，研究重点不在于单一功能实现，而在于如何将感知、认知与反馈整合为一套支持长期互动的交互逻辑，使机器人能够根据老年人的状态变化与使用情境，动态调整陪伴方式与互动内容，从而增强使用的自然性、连续性与情感连贯性，提升老人的接受度与持续使用意愿，更好地回应老年人在健康、认知与情感层面的综合需求。
1.实现基于多模态感知的老年状态理解
依托陪伴型机器人作为具身智能载体，研究如何通过老人的表情、姿态、行为节奏、互动响应等多模态线索，实现对老年人身心状态的持续、整体性理解。重点关注在非侵入、低干扰的条件下，将健康监测与状态识别自然嵌入陪伴互动过程，避免显性“监测”带来的心理压力。
2.研究具备适应性的认知训练与陪伴机制
围绕老年人在不同情境与状态下的参与能力与心理承受度，探索认知训练在内容强度、节奏与触发方式上的动态调整策略。弱化训练感与任务感，使认知活动从“被安排的训练任务”转变为“可被接受的日常互动”，避免因过度干预而引发疲劳或抵触。并希望在持续互动中逐步形成对老年用户行为模式与偏好的理解，并通过差异化的反馈方式建立稳定、连贯的互动关系。
二、设计（研究）现状和发展趋势
1.老年认知训练与干预研究现状
大量系统综述与随机对照试验表明，系统化的认知训练能够在一定程度上改善老年人的执行功能、记忆能力与日常生活功能，并具有一定的长期保持效果。早期代表性研究如 ACTIVE研究显示，不同类型的认知训练可对特定认知能力产生持续影响，且部分效果在多年后仍然存在（Ball et al., 2002；Rebok et al., 2014）。后续研究进一步从神经可塑性角度论证了老年期仍具备通过训练改善认知功能的潜力（Andrews et al., 2019）。
近年来，研究逐渐从单一认知域训练转向更贴近真实生活情境的干预形式。例如，双任务训练（Dual-task Training）和认知-身体结合训练（Combined Cognitive and Physical Training, CECT）被证实在改善整体认知表现方面具有更优效果，尤其对存在轻度认知障碍的老年人群更为显著（Lauenroth et al., 2022；Li et al., 2024）。这些研究表明，将认知训练嵌入更自然的行为活动中，是提升干预有效性的重要方向。然而，现有认知训练研究多集中于训练效果本身，训练过程往往以明确任务和测试为导向，容易强化“被训练”的角色定位，在实际应用中面临参与动机不足和长期坚持困难的问题。
2.认知训练系统的交互形式与自适应趋势
在交互形式层面，近年来的研究开始关注通过游戏化与自适应机制提升老年人的参与意愿。其中，动态难度调整（Dynamic Difficulty Adjustment, DDA）被证明能够根据用户表现实时调整任务难度，从而维持挑战与能力之间的平衡，提升训练的持续性与积极性（García-Betancourt et al., 2023）。
此外，沉浸式与空间化交互逐渐成为老年认知训练系统的重要发展方向。在休闲化、低压力的交互情境中，老年人能够获得较好的使用体验和一定的认知改善效果（Castellote-Caballero et al., 2025）。这类研究强调减少抽象操作与认知负担，通过更直观的交互方式支持认知活动。尽管如此，现有系统多以屏幕、头显或明确的训练设备为载体，仍然存在设备侵入性强、使用门槛较高的问题，难以融入老年人的日常生活情境。
3.老年健康监测与多模态感知技术发展
随着计算机视觉与信号处理技术的发展，非接触式生理监测逐渐成为老年健康管理的重要研究方向。基于面部视频的远程心率测量（rPPG）技术已在复杂光照与真实场景下验证了其可行性，为无感、持续的健康监测提供了技术基础（Li et al., 2014）。在此基础上，多模态感知逐渐成为智能交互系统的重要趋势，通过融合生理信号、行为动作与情绪线索，为系统提供更全面的用户状态信息。这类技术为从“被动记录”向“状态理解与主动响应”转变提供了可能，但在老年应用场景中，如何避免“被监测”的心理压力仍有待进一步探索。
4.社交与陪伴机器人研究现状与发展趋势
社交与陪伴机器人被广泛应用于老年人群体的情感支持与孤独缓解研究中。多项实证研究和荟萃分析表明，陪伴机器人在减轻孤独感、提升情绪状态方面具有积极效果（Mehrabi & Ghezelbash, 2022）。引入情绪感知与人工情感智能的机器人系统，能够通过更贴近情绪状态的反馈方式提升老年人的互动体验（Abdollahi et al., 2023）。然而，现有陪伴机器人研究多以情感交流或娱乐为核心，健康监测与认知训练往往以独立模块存在，缺乏统一的交互逻辑与长期适应机制。同时，部分机器人在设计上仍以“照护”或“管理”为隐性前提，容易削弱老年人的主体感与平等感，影响长期接受度。
5.小结与发展趋势
综上所述，当前研究在认知训练有效性、非接触式健康监测以及陪伴机器人情感价值等方面已形成较为充分的理论与技术基础，但在实际应用中仍存在以下趋势性挑战与发展方向：一是从“功能叠加”转向“情境化整合”，将健康监测、认知训练与陪伴行为自然融合于日常互动中；二是从任务导向转向状态导向，通过多模态感知理解老年人的真实状态，支持更柔性的干预；三是构建具备适应性与情感连贯性的具身交互逻辑，提升老年人的接受度与持续使用意愿。在此背景下，以陪伴型机器人作为具身智能载体，探索健康监测与认知训练在长期陪伴情境中的融合式交互机制，具有明确的研究价值与现实意义。
三、设计（研究）的重点和难点，拟采用的途径（研究手段）
1.研究重点
第一、面向老年日常情境的状态感知与健康风险提示机制。
区别于以单一生理指标为核心的健康监测产品，本研究关注如何整合多源感知信息，对老年人的整体状态进行理解。通过结合机器视觉获取的表情、行为等信息，以及交互过程中产生的操作行为、认知训练表现等数据，探索对老年人身心状态的综合估算方式。研究重点不在于精确诊断某一具体疾病，而在于通过与个体日常状态的对比，识别可能存在的异常变化趋势，为潜在健康风险提供辅助性的提示，从而实现“低干扰、长期在场”的健康监测目标。
第二、基于状态变化的认知训练与情感陪伴的自适应调节。
在状态感知的基础上，本课题进一步关注陪伴机器人如何根据老年人的状态变化，动态调整认知训练与情感陪伴的介入方式。研究重点在于探索认知训练的强度、频率与形式，以及情感陪伴的互动方式，如何随老年人状态而变化，从而避免“被训练”“被打扰”的感受，使认知训练与陪伴行为更自然地融入日常生活，提升老年人的接受度与持续使用意愿。
2.研究难点
第一、信息获取的稳定性与可靠性
在实际养老场景中，老年人的行为与环境条件具有高度不确定性，如非正面视角、光照变化、多人共存以及姿态与活动频繁变化等，这些因素都会影响基于视觉与行为数据的感知结果。如何在复杂情境下获取相对稳定、可用的感知信息，是状态估算的基础难点。
第二、状态估算模型的构建
多模态感知与交互数据之间存在异质性与模糊性，不同状态信号往往无法形成一一对应关系。研究难点在于如何利用这些多模态数据，构建一种以“趋势与异常”为核心的状态估算模型，在避免过度解读个体行为的同时，形成足以支撑交互决策的状态参考。
第三、基于状态的交互强度与形式调节策略
在健康监测与认知训练介入过程中，不同强度与频率的认知训练和情感反馈对老年人心理接受度的影响存在差异。过弱的反馈可能无法形成有效支持，而过强的提醒或引导又容易引发老年人的抵触情绪。研究难点在于避免简单的“状态—反应”对应关系，而是设计出具有缓冲与渐变特征的调节机制，使系统反应更加柔性、连贯。
第四、主动交互介入的时机与方式选择
陪伴型机器人需要把握好主动介入的尺度与时机，过于频繁或时机不当的主动交互容易引发老年人的抵触情绪。如何在状态变化的基础上判断合适的介入时机，并选择不打断、不施压的交互方式，不破坏老年人对尊严、情感安全与自主性的心理预期，避免将陪伴型机器人异化为“监控装置”或“训练工具”。
3.拟采用的途径（研究手段）
第一、基于文献与开源实践的状态感知逻辑拆解与设计转译
本研究并不试图从零构建复杂的医学级状态识别模型，而是通过系统梳理已有文献与开源项目中关于老年人生理状态、情绪状态与认知参与度的研究成果，提炼其中可被设计使用的状态判断思路。研究重点不在于算法本身的创新，而在于分析不同研究中常用的状态线索（如心率趋势、行为节奏变化、认知任务表现波动等）是如何被用于状态估计的，并将这些思路转译为适用于陪伴机器人交互设计的“状态参考信号”。通过这一方式，建立一个基于多模态信息的状态估算框架，用于支持后续交互调节设计，而非追求精确诊断结论。
第二、基于趋势与阈值的状态估算原型构建与迭代。
本研究采用以趋势与阈值判断为核心的状态估算方式，而非复杂的深度学习模型。
具体而言，通过对情绪变化、心率波动、互动频率、认知训练得分变化等多种信息进行归一化与趋势分析，构建一套“相对状态判断”逻辑，例如：与个体自身平常状态相比的异常变化、连续多次交互中参与度或表现的显著下降、生理与行为信号同时出现异常的叠加情况。该方式强调“相对变化”而非绝对数值，既降低实现难度，也更符合老年健康监测中“早期提醒而非诊断”的设计定位。状态估算逻辑将在原型测试过程中根据实际使用情况进行调整与简化。
第三、基于状态驱动的认知训练与陪伴交互策略设计。
在获得状态参考信号的基础上，本研究重点探索如何将其用于指导交互行为的动态调整，而非作为单独展示的数据结果。通过设计不同状态下的交互策略组合（如降低认知任务难度、延长反应时间、减少训练频率、转向情感陪伴或休息提示等），构建一套状态—交互响应对应关系。该研究途径的核心在于验证：当系统根据老年人状态变化主动调整互动方式时，是否能够降低训练负担感、减少抵触情绪，并提升持续参与意愿，而非单纯追求训练强度或效率。
第三、通过低次数但高针对性的真实用户测试验证设计有效性。
本研究计划在原型完成后，开展可用性与体验测试。测试重点不在于长期干预效果，而在于短期使用中：老年人是否理解并接受这种交互形式、是否愿意参与认知训练与陪伴互动、状态变化触发的交互调整是否被感知为“贴心”而非“干扰”。测试将结合简化的认知评估工具（如 MoCA 或 MMSE 前后对比）、行为表现观察及 SUS 等主观问卷，作为设计方案有效性的辅助验证。测试结果将直接用于原型迭代，形成“设计—验证—优化”的完整研究闭环。
