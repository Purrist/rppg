# 结合健康监测与认知训练的老年陪伴机器人交互体验设计研究

## 一、项目概述

### 1. 开发总目标

本项目为工业设计专业大学生的毕业设计，旨在开发一个面向机构养老场景的多模态交互陪伴机器人系统原型，具备 "**投影式认知交互 + 非接触式健康监测 + 情感陪伴机制**" 的联动框架，产出 **基于老人状态感知的自适应交互系统**。

### 2. 核心功能与预期架构

系统采用分层架构设计，实现三个核心能力的联动：

| 层级 | 主要功能 | 核心模块 |
|------|----------|----------|
| **感知层** | 数据采集与预处理 | 平板端摄像头（生理监测）、地面交互摄像头（外接、投影交互） |
| **状态理解层** | 状态分析与判断 | 生理状态趋势分析、情绪与参与度评估、异常行为检测 |
| **交互与决策层** | 智能决策与反馈 | 训练难度调节、情感反馈生成、状态参考输出 |

### 3. 预期实现方案

- **硬件配置**：安卓平板（前置摄像头）+ 投影仪 + 外置摄像头
- **软件架构**：前后端分离，后端Python，前端Nuxt-Vue
- **技术路径**：OpenCV (捕获) + Mediapipe (对齐) + DeepFace (分析) + Socket.IO (传输)
- **交互方式**：老人通过脚步/站位/停留与投影界面交互

## 二、系统架构与功能设计

### 1. 感知层

#### 平板端摄像头（网络摄像头）

- **功能**：rPPG心率估计 + 情绪识别 + 姿态检测 + 注意力评估
- **设备**：安卓平板（荣耀平板）IP Webcam
- **默认URL**：`http://192.168.137.97:8080/video`
- **技术实现**：
  - rPPG心率估计：通过面部颜色变化提取心率信号
  - 情绪识别：Mediapipe面部网格 + DeepFace情绪分析
  - 姿态检测：上半身姿态评估与参与度分析
  - 注意力评估：眼部状态（眨眼频率、注视方向）分析
  - 人体识别：是否有人，有多少人，人与设备的距离，人脸识别

#### 地面交互摄像头（外接摄像头）

- **功能**：认知训练互动中识别投影画面内的脚踩/手部遮挡动作
- **设备**：外置摄像头
- **技术实现**：
  - 彩色区域检测：识别投影界面的交互区域
  - 手部/脚部检测：MediaPipe Hands检测交互行为
  - 交互判定：基于停留时间的交互确认

#### 当前硬件替代方案

- 使用手机摄像头（ipwebcam：<http://192.168.137.113:8080/video>）代替外接摄像头，电脑屏幕模拟地面投影。
- 用户用手遮挡某区域≥2秒等价于"脚踩投影区域"
- 手部遮挡检测替代脚踩踏检测

### 2. 状态理解层

#### 生理状态趋势判断

- rPPG心率监测与HRV分析
- 疲劳程度评估
- 活动量与活动节奏分析

#### 情绪与参与度变化趋势

- 多模态情绪识别（面部表情 + 姿态）
- 注意力与反应力评估
- 参与度动态监测

#### 异常或疲劳行为信号

- 异常心率检测
- 长时间静止/活动异常检测
- 疲劳与注意力下降预警

### 3. 交互与决策层

#### 认知训练参数调节

- 难度动态调整
- 节奏自适应调节
- 持续时间智能控制

#### 情感反馈方式调节

- 语音语气调整
- 鼓励/放缓/休息提示
- 个性化内容推荐

#### 状态参考信息输出

- 实时状态监测报告
- 历史数据统计与分析
- 异常状态预警

## 三、UI与交互设计

### 1. 平板端UI（2560*1600，16:10比例）

原则：全屏锁定，禁止出现滚动条和白边框。所有页面需适配 app.vue 中的 .tablet-frame 容器。

#### 主页

- 日期天气显示
- 语音通话
- 一键呼叫
- 健康、娱乐、认知三大入口（侧边栏）
- 智能服务助手（阿康）

#### 健康板块

- 健康看板：情绪健康、睡眠健康、活动量、心率、HRV等
- 运动课程：八段锦、太极等
- 生活建议：饮食建议等

#### 娱乐板块

- 影视功能
- 音乐功能（民歌、戏曲、收音机等）
- 舞蹈功能（广场舞、交际舞）
- 报纸杂志资讯
- 回忆相册

#### 认知与学习板块

- 认知训练/游戏（色词测试、打地鼠等）
- 认知看板：训练时长、效果、趋势等
- 学习内容：园艺种植、烹饪烘焙、琴棋书画等

### 2. 投影端UI（认知训练界面）

- 通过投影仪投射到地面
- 大尺寸、低精度操作区域
- 主要显示：
  - 认知训练游戏内容
  - 交互区域（颜色块、按钮等）
  - 实时得分与进度显示

### 3. 交互方式

#### 色词测试示例

- 投影界面显示带颜色的文字（如红色的"黄"）
- 老人通过脚踩或停留选择文字颜色
- 系统实时反馈正确/错误

## 四、技术栈

### 后端

- Python 3.10.x
- Flask-SocketIO: 异步通讯（Windows 下强制使用 threading 模式）。
- OpenCV（图像处理）
- MediaPipe（姿态+手势识别）
- DeepFace（情绪识别）
- Socket.IO（实时通信）
- Scipy（信号处理）
- TensorFlow 2.15.1（深度学习推理）

### 前端

- Vue 3
- Nuxt 3
- Socket.IO Client: 实时图像渲染（Base64 模式）。
- Chart.js（数据可视化）

## 五、开发计划

### 阶段一

### 阶段二

## 六、当前实现状态

### 1. 已实现功能

#### 视频处理与识别

- 平板摄像头视频流获取与处理
- rPPG心率估计（不准确）
- 情绪识别（不准确）

### 2. 存在的问题与挑战

#### 技术问题

- 非正脸识别准确率需进一步提高

#### 功能完善

- 更多认知训练游戏的开发

#### 硬件限制

- 暂无投影仪和外置摄像头
- 当前使用手机IP Webcam替代

## 七、下一步计划

### 1. 近期计划（1-2周）

### 2. 中期计划（2-4周）

### 3. 长期计划（4-8周）


### 连接配置

- **默认URL**：
  - 平板摄像头：`http://192.168.137.97:8080/video`
  - 投影摄像头（暂时用手机摄像头代替）：`http://192.168.137.113:8080/video`

## 九、技术路径与环境依赖

### 关键技术实现

1. **双线程架构**：分离捕获线程和分析线程，确保前端画面流畅显示

2. **16:10固定布局**：所有页面采用2560*1600固定比例，确保跨设备显示一致性

## 十、项目结构

├── backend (系统后端)
│   ├── app.py              # 服务入口与 SocketIO 线程管理
│   ├── tablet_processor.py # 核心感知引擎 (rPPG、情绪识别、ROI 锁定)
│   ├── screen_processor.py # 投影交互处理
│   ├── state_manager.py    # 自适应逻辑决策中心
│   └── training_history.json
├── frontend (Nuxt 前端)
│   ├── pages
│   │   ├── index.vue       # 首页 (三大入口)
│   │   ├── health.vue      # 健康监测与运动课程
│   │   ├── entertainment.vue # 影视/音乐/相册
│   │   ├── learning.vue    # 认知训练与学习入口
│   │   ├── training.vue    # 认知训练实操界面 (Stroop)
│   │   ├── developer.vue   # 开发者诊断后台 (白底)
│   │   └── settings.vue    # 系统设置
│   ├── app.vue             # 16:10 全局框架与 Akon 助手逻辑
│   └── nuxt.config.ts
├── README.md               # 本开发手册
└── instruction.md          # 毕业设计总体说明